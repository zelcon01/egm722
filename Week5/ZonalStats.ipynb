{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "latest-anime",
   "metadata": {},
   "source": [
    "# zonal statistics using rasterstats\n",
    "\n",
    "## overview\n",
    "\n",
    "Up to now, we have worked with either vector data or raster data, but we haven't really used them together. In this week's practical, we'll learn how we can combine these two data types, and see some examples of different analyses, such as zonal statistics or sampling raster data, that we can automate using python.\n",
    "\n",
    "## objectives\n",
    "-  learn how to use `rasterstats` to perform zonal statistics\n",
    "-  use the `zip` built-in to combine iterables such as lists\n",
    "-  learn how to handle exceptions using `try` ... `except` blocks\n",
    "-  rasterize polygon data using `rasterio`\n",
    "-  learn how to mask and select (index) rasters using vector data\n",
    "-  see additional plotting examples using `matplotlib`\n",
    "\n",
    "## data provided\n",
    "\n",
    "In the data\\_files folder, you should have the following:\n",
    "-  LCM2015_Aggregate_100m.tif\n",
    "-  NI_DEM.tif\n",
    "\n",
    "\n",
    "## getting started\n",
    "\n",
    "In this practical, we'll look at a number of different GIS tasks related to working with both raster and vector data in python, as well as a few different python and programming concepts. To get started, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterstatsS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-water",
   "metadata": {},
   "source": [
    "## zonal statistics\n",
    "In GIS, [_zonal statistics_](https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-analyst/how-zonal-statistics-works.htm) is a process whereby you calculate statistics for the pixels of a raster in different groups, or zones, defined by properties in another dataset. In this example, we're going to use the Northern Ireland County border dataset from Week 2, along with a re-classified version of the Northern Ireland [Land Cover Map](https://catalogue.ceh.ac.uk/documents/47f053a0-e34f-4534-a843-76f0a0998a2f) 2015[<sup id=\"fn1-back\">1</sup>](#fn1 \"footnote 1\").\n",
    "\n",
    "The Land Cover Map tells, for each pixel, what type of land cover is associated with a location - that is, whether it's woodland (and what kind of woodland), grassland, urban or built-up areas, and so on. For our re-classified version of the dataset, we're working with the aggregate class data, re-sampled to 100m resolution from the original 25m resolution.\n",
    "\n",
    "The raster data type is *unsigned integer* with a *bitdepth* of 8 bits - that is, it has a range of possible values from 0 to 255. Even though it has this range of possible values, we only use 10 (11) of them:\n",
    "\n",
    "| Raster value | Aggregate class name       |\n",
    "| :------------|:---------------------------|\n",
    "| 0            | No Data                    |\n",
    "| 1            | Broadleaf woodland         |\n",
    "| 2            | Coniferous woodland        |\n",
    "| 3            | Arable                     |\n",
    "| 4            | Improved grassland         |\n",
    "| 5            | Semi-natural grassland     |\n",
    "| 6            | Mountain, heath, bog       |\n",
    "| 7            | Saltwater                  |\n",
    "| 8            | Freshwater                 |\n",
    "| 9            | Coastal                    |\n",
    "| 10           | Built-up areas and gardens |\n",
    "\n",
    "In the cell below, we'll first define a **list** of landcover class names, in the order shown in the table above. Then, we'll use `range()` to create a list of values from 1 to 10, corresponding to the raster value of each landcover class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa9a5d-fb98-45ac-854c-eabbbb171cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the landcover class names in a list\n",
    "names = ['Broadleaf woodland', 'Coniferous woodland', 'Arable', 'Improved grassland', 'Semi-natural grassland', \n",
    "         'Mountain, heath, bog', 'Saltwater', 'Freshwater', 'Coastal', 'Built-up areas and gardens']\n",
    "\n",
    "values = range(1, 11) # get numbers from 1-10, corresponding to the landcover values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7badea32-84fa-413b-bd3d-899c6e3ba7e2",
   "metadata": {},
   "source": [
    "Next, we'll use a combination of the `zip()` built-in function ([documentation](https://docs.python.org/3/library/functions.html#zip)), along with `dict()` ([documentation](https://docs.python.org/3/library/functions.html#func-dict)), to create a **dict** object of **key**/**value** pairs that maps each raster value (the **key**) to a class name (the **value**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb40a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover_names = dict(zip(values, names)) # create a dict of landcover value/name pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef94dbeb",
   "metadata": {},
   "source": [
    "We'll use this later on, when we want to make our outputs more readable/understandable.\n",
    "\n",
    "In this part of the practical, we'll try to work out the percentage of the entire country, and of each county individually, that is covered by each of these different landcovers. \n",
    "\n",
    "To start, we'll load the `LCM2015_Aggregate_100m.tif` raster, as well as the counties shapefile from Week 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the land cover raster and read the data\n",
    "with rio.open('data_files/LCM2015_Aggregate_100m.tif') as dataset:\n",
    "    xmin, ymin, xmax, ymax = dataset.bounds \n",
    "    crs = dataset.crs\n",
    "    landcover = dataset.read(1)\n",
    "    affine_tfm = dataset.transform\n",
    "\n",
    "# now, load the county dataset from the week 2 folder\n",
    "counties = gpd.read_file('../Week2/data_files/Counties.shp').to_crs(crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947dd69e-a98c-4de1-932a-7e9616f7c570",
   "metadata": {},
   "source": [
    "Next, we'll define a function that takes an array, and returns a **dict** object containing the count (number of pixels) for each of the unique values in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique(array, names, nodata=0):\n",
    "    '''\n",
    "    Count the unique elements of an array.\n",
    "\n",
    "    :param array: Input array\n",
    "    :param names: a dict of key/value pairs that map raster values to a name\n",
    "    :param nodata: nodata value to ignore in the counting\n",
    "    \n",
    "    :returns count_dict: a dictionary of unique values and counts\n",
    "    '''\n",
    "    count_dict = dict() # create the output dict\n",
    "    for val in np.unique(array): # iterate over the unique values for the raster\n",
    "        if val == nodata: # if the value is equal to our nodata value, move on to the next one\n",
    "            continue\n",
    "        count_dict[names[val]] = np.count_nonzero(array == val)\n",
    "    return count_dict # return the now-populated output dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-immune",
   "metadata": {},
   "source": [
    "Here, we have three input parameters: the first, `array`, is our array (or raster data). The next, `names`, is a dict of **key**/**value** pairs to provide human-readable names for each raster value. Finally, `nodata` is the value of the input array that we should ignore. \n",
    "\n",
    "The first line of the function defines an empty **dict**:\n",
    "\n",
    "```python\n",
    "count_dict = dict()\n",
    "```\n",
    "\n",
    "This is the empty container into which we'll place the **key**/**value** pairs corresponding to the count for each landcover class.\n",
    "\n",
    "Next, using `numpy.unique()` ([documentation](https://numpy.org/doc/stable/reference/generated/numpy.unique.html)), we get an array containing the unique values of the input array. \n",
    "\n",
    "Note that this works for data like this raster, where we have a limited number of pre-defined values. For something like a digital elevation model, which represents continuous floating-point values, we wouldn't want to use this approach to bin the data - we'll see how we can handle continuous data later on.\n",
    "\n",
    "For each of the different unique values `val`, we find all of the locations in `array` that have that value (`array == val`). Note that this is actually a boolean array, with values of either `True` where `array == val`, and `False` where `array != val`. `numpy.count_nonzero()` ([documentation](https://numpy.org/doc/stable/reference/generated/numpy.count_nonzero.html)) then counts the number of non-zero (in this case, `True`) values in the array - that is, this:\n",
    "\n",
    "```python\n",
    "np.count_nonzero(array == val)\n",
    "```\n",
    "\n",
    "tells us the number of pixels in `array` that are equal to `val`. We then assign this to our dictionary with a key that is a __str__ representation of the value, before returning our `count_dict` variable at the end of the function.\n",
    "\n",
    "Run the cell below to run the function on our `landcover` raster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65931094-8f0a-43d3-84a7-1b42fce091b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover_count = count_unique(landcover, landcover_names)\n",
    "print(landcover_count) # show the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-nursery",
   "metadata": {},
   "source": [
    "<span style=\"color:#009fdf;font-size:1.1em;font-weight:bold\">Exercise: can you work out the percentage area of Northern Ireland that is covered by each of the 10 landcover classes?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by using count_unique to get the number of pixels corresponding to each landcover class\n",
    "\n",
    "# now, get the total number of pixels in the image that aren't nodata\n",
    "# hint: use np.count_nonzero()\n",
    "\n",
    "# now, iterate over the dictionary items to express the number of pixels as a percentage of the total pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-dayton",
   "metadata": {},
   "source": [
    "Now, let's have a look at the help for `rasterstats.gen_zonal_stats()` ([documentation](https://pythonhosted.org/rasterstats/rasterstats.html#rasterstats.gen_zonal_stats)), which will tell us how we can use `rasterstats` to get zonal statistics for a raster and vector geometry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f744ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(rasterstats.gen_zonal_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a84498e",
   "metadata": {},
   "source": [
    "In the output of the cell above, you should see the usage for `rasterstats.gen_zonal_stats()`, which is the same as the usage for `rasterstats.zonal_stats()`. Have a look at the documentation - we'll go over an example below, but there are many more useful features that we won't go into in the tutorial.\n",
    "\n",
    "In the following cell, we use `rasterstats.zonal_stats()` ([documentation](https://pythonhosted.org/rasterstats/manual.html#zonal-statistics)) with our `counties` and `landcover` datasets to do the same exercise as above (counting unique pixel values).\n",
    "\n",
    "Rather than counting the pixels in the entire raster, however, we want to count the number of pixels with each land cover value that fall within a specific area defined by each of the features in the  `counties` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_stats = rasterstats.zonal_stats(counties, # the shapefile to use\n",
    "                                       landcover, # the raster to use - here, we're using the numpy array loaded using rasterio\n",
    "                                       affine=affine_tfm, # the geotransform for the raster\n",
    "                                       categorical=True, # whether the data are categorical\n",
    "                                       category_map=landcover_names,\n",
    "                                       nodata=0 # the nodata value for the raster\n",
    "                                      )\n",
    "\n",
    "print(type(county_stats)) # county_stats is a list of dict objects\n",
    "print(county_stats[0]) # shows the landcover use for county tyrone (index 0 in counties geodataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-balance",
   "metadata": {},
   "source": [
    "## the zip built-in\n",
    "\n",
    "We introduced the `zip()` built-in function above, but it's worth discussing this powerful and useful function in a bit more detail. \n",
    "\n",
    "In Python 3, `zip()` returns a **zip** object that combines elements from each of the iterable objects passed as arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4]\n",
    "y = ['a', 'b', 'c', 'd']\n",
    "\n",
    "print(zip(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ff4ee",
   "metadata": {},
   "source": [
    "We have seen something similar with **iterator** objects before - for example, the output of `range()` is an **iterator**. As we have seen, we can *iterate* over the items of the **iterator** object, or we can use something like `list()` to convert the **iterator** into another type of object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(x, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06857750",
   "metadata": {},
   "source": [
    "And, as we saw above, we can also pass the output of `zip()` to `dict()`, to create a **dict** of **key**/**value** pairs - this is an efficient way to create a **dict** object from two **list** objects of different items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict(zip(x, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-saskatchewan",
   "metadata": {},
   "source": [
    "One thing to keep in mind, though, is that with `zip(x, y)`, each of the elements of `x` is paired with the corresponding element from `y`. If `x` and `y` are different lengths, `zip(x, y)` will only use up to the shorter of the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3]\n",
    "\n",
    "list(zip(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a378bb08",
   "metadata": {},
   "source": [
    "As a final example, we can also use `zip()` to combine more than two iterables - we're not limited to a single pair of iterables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4]\n",
    "y = ['a', 'b', 'c', 'd']\n",
    "z = ['i', 'ii', 'iii', 'iv']\n",
    "\n",
    "print(list(zip(x, y, z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-locator",
   "metadata": {},
   "source": [
    "Now, let's use `zip()` to create a **dict** that returns the landcover stats for each county, given the county name.\n",
    "\n",
    "First, we can use a *list comprehension* to get a list of the county names, formatted using `str.title()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [n.title() for n in counties['CountyName']] # use str.title() because we're not shouting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-dynamics",
   "metadata": {},
   "source": [
    "Now, we use `dict()` and `zip()` to create the **dict** object of landcover stats by county:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_dict = dict(zip(names, county_stats))\n",
    "print(county_dict['Tyrone']) # should be the same output as before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-multiple",
   "metadata": {},
   "source": [
    "## handling Exceptions with try ... except\n",
    "\n",
    "Now, let's add information about the percent landcover to the `counties` table. We'll start by using creating a __dict__ that takes the full landcover class name, and shortens it so that it can be used as a column header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_names = ['broadleaf', 'coniferous', 'arable', 'imp_grass', 'nat_grass', \n",
    "               'mountain', 'saltwater', 'freshwater', 'coastal', 'built_up']\n",
    "short_dict = dict(zip(landcover_names.values(), short_names)) # use dict and zip with the full names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-ultimate",
   "metadata": {},
   "source": [
    "Now, we can use this to populate the data table with new columns for each landcover class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in counties.iterrows(): # use iterrows to iterate over the rows of the table\n",
    "    county_data = county_dict[row['CountyName'].title()] # get the landcover data for this county\n",
    "    for name in landcover_names.values(): # iterate over each of the landcover class names       \n",
    "        counties.loc[ind, short_dict[name]] = county_data[name] # add the landcover count to a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bfa704-83de-430a-8739-6ac5c4b3a1a3",
   "metadata": {},
   "source": [
    "What happened here? \n",
    "\n",
    "From the error message above, we can see that there is no entry for `Saltwater` in the data for this county (Tyrone): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1b9b1-bae2-4131-9d2b-3bb2e6aa5c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row['CountyName'].title()) # show the county name that caused the error\n",
    "print('Saltwater' in county_dict[row['CountyName'].title()].keys()) # is Saltwater a valid key for this county?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d39ed73-622a-4d70-a3c2-7c8088e25d6a",
   "metadata": {},
   "source": [
    "Because `Saltwater` is not in the list of **key** values for this **dict**, when we try to use `Saltwater` as a **key** in the `county_data` dictionary, it raises a **KeyError**. \n",
    "\n",
    "The problem that we have here is that we don't necessarily have all landcover classes represented in every county. We shouldn't expect to, either - County Tyrone is an inland county, so it makes sense that it wouldn't have any saltwater areas.\n",
    "\n",
    "One way to handle this could be to insert an **if**/**else** block to check that the landcover class is present in the **dict** before trying to access it. This would check whether the value of `name` is a **key** of `county_data` - if it isn't, then it will add a value of 0 to the table for that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6cd18-f75b-4261-98a5-0c886ba60c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in counties.iterrows(): # use iterrows to iterate over the rows of the table\n",
    "    county_data = county_dict[row['CountyName'].title()] # get the landcover data for this county\n",
    "    for name in landcover_names.values(): # iterate over each of the landcover class names\n",
    "        if name in county_data.keys(): # check that name is a key of county_data\n",
    "            counties.loc[ind, short_dict[name]] = county_data[name] # add the landcover count to a new column\n",
    "        else:\n",
    "            counties.loc[ind, short_dict[name]] = 0 # if name is not present, value should be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-mailman",
   "metadata": {},
   "source": [
    "Another option is to use a [`try` ... `except`](https://realpython.com/python-exceptions/#the-try-and-except-block-handling-exceptions) block to \"catch\" and handle an exception:\n",
    "\n",
    "```python\n",
    "\n",
    "try:\n",
    "    # run some code\n",
    "except:\n",
    "    # run this if the try block causes an exception\n",
    "```\n",
    "\n",
    "In general, it's [not recommended](https://www.python.org/dev/peps/pep-0008/#programming-recommendations) to just have a bare `except:` clause, as this will make it harder to interrupt a program. In our specific case, we only want the interpreter to ignore `KeyError` exceptions - if there are other problems, we still need to know about those.\n",
    "\n",
    "In our example, the `try` ... `except` block looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018598b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in counties.iterrows(): # use iterrows to iterate over the rows of the table\n",
    "    county_data = county_dict[row['CountyName'].title()] # get the landcover data for this county\n",
    "    for name in landcover_names.values(): # iterate over each of the landcover class names\n",
    "        try:\n",
    "            counties.loc[ind, short_dict[name]] = county_data[name] # add the landcover count to a new column\n",
    "        except KeyError: # we can ignore KeyErrors, because this just means the landcover class has a value of 0\n",
    "            counties.loc[ind, short_dict[name]] = 0 # if name is not present, value should be 0.\n",
    "\n",
    "counties # just to show the table in the output below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca9c41",
   "metadata": {},
   "source": [
    "Now, we can see that the table has had an additional 10 columns added (one for each landcover class), with each column being filled with the number of pixels in each county that are classified as that landcover class.\n",
    "\n",
    "As one final step, let's update the table so that the value corresponds to the percentage of each county's area covered by each landcover class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in counties.iterrows(): # iterate over the rows of the table\n",
    "    counties.loc[ind, short_names] = 100 * row[short_names] / row[short_names].sum()\n",
    "counties # just to show the table in the output below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-factory",
   "metadata": {},
   "source": [
    "In the above, you can see that we've _indexed_ the table using the list of column names `short_name`, which ensures that we only select the columns we're interested in.\n",
    "\n",
    "<span style=\"color:#009fdf;font-size:1.1em;font-weight:bold\">Looking at the table above, what landcover class dominates each county? Does this make sense, given what you know about Northern Ireland?</span>\n",
    "\n",
    "As a final exercise, modify the cell below so that each cell represents the total area (in square km) covered by each landcover class, rather than the number of pixels or the percent area of each county. \n",
    "\n",
    "As a small hint, you should only need to change a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in counties.iterrows(): # use iterrows to iterate over the rows of the table\n",
    "    county_data = county_dict[row['CountyName'].title()] # get the landcover data for this county\n",
    "    for name in landcover_names.values(): # iterate over each of the landcover class names\n",
    "        try:\n",
    "            counties.loc[ind, short_dict[name]] = county_data[name] # add the landcover count to a new column\n",
    "        except KeyError:\n",
    "            counties.loc[ind, short_dict[name]] = 0 # if name is not present, value should be 0.\n",
    "\n",
    "counties # just to show the table in the output below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-appeal",
   "metadata": {},
   "source": [
    "## rasterizing vector data using rasterio\n",
    "`rasterstats` provides a nice tool for quickly and easily extracting zonal statistics from a raster using vector data. Sometimes, though, we might want to *rasterize* our vector data - for example, in order to mask our raster data, or to be able to select pixels. To do this, we can use the `rasterio.features` module ([documentation](https://rasterio.readthedocs.io/en/latest/api/rasterio.features.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio.features # we have imported rasterio as rio, so this will be rio.features (and rasterio.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a6847a-d78f-4e64-8e25-07d934feb657",
   "metadata": {},
   "source": [
    "`rasterio.features`has a number of different methods, but the one we are interested in here is `rasterize()` ([documentation](https://rasterio.readthedocs.io/en/latest/api/rasterio.features.html#rasterio.features.rasterize)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65ede8-9cd2-465b-8041-f83e63e893da",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(rio.features.rasterize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-prisoner",
   "metadata": {},
   "source": [
    "Here, we pass an **iterable** object (**list**, **tuple**, **array**, etc.) that contains (`geometry`, `value`) pairs. `value` determines the pixel values in the output raster that the `geometry` overlaps. If we don't provide a `value`, it takes the `default_value` or the `fill` value.\n",
    "\n",
    "So, to create a rasterized version of our county outlines, we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51341a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = list(zip(counties['geometry'], counties['COUNTY_ID'])) # get a list of geometry, value pairs\n",
    "county_mask = rio.features.rasterize(shapes=shapes, # the list of geometry/value pairs\n",
    "                                     fill=0, # the value to use for cells not covered by any geometry\n",
    "                                     out_shape=landcover.shape, # the shape of the new raster\n",
    "                                     transform=affine_tfm) # the geotransform of the new raster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f9f85e",
   "metadata": {},
   "source": [
    "The first line uses `zip()` and `list()` to create a list of (__geometry__, __value__) pairs, and the second line actually creates the rasterized array, `county_mask`. \n",
    "\n",
    "Note that in the call to `rasterio.features.rasterize()`, we have to set the output shape (`out_shape`) of the raster, as well as the `transform` - that is, how we go from pixel coordinates in the array to real-world coordinates. \n",
    "\n",
    "Since we want to use this rasterized output with our `landcover`, we use the `shape` of the `landcover` raster, as well as its `transform` (`affine_tfm`) - that way, the outputs will line up as we expect. \n",
    "\n",
    "The cell below will display the `county_mask` raster in a `matplotlib` **Figure**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "im = ax.imshow(county_mask) # visualize the rasterized output\n",
    "fig.colorbar(im) # show a colorbar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-brooks",
   "metadata": {},
   "source": [
    "As you can see, this provides us with an **array** whose values correspond to the `COUNTY_ID` of the county feature at that location (check the `counties` **GeoDataFrame** again to see which county corresponds to which ID). In the next section, we'll see how we can use arrays like this to investigate our data further.\n",
    "\n",
    "## masking and indexing rasters\n",
    "So far, we've seen how we can index an array (or a list, a tuple, ...) using simple indexing (e.g., `myList[0]`) or _slicing_ (e.g., `myList[2:4]`). `numpy` arrays, however, can [actually be indexed](https://numpy.org/doc/stable/reference/arrays.indexing.html) using other arrays of type `bool` (the elements of the array are boolean (`True`/`False`) values) - similar to how we have used conditional statements to select rows from a **GeoDataFrame**. \n",
    "\n",
    "In this section, we'll see how we can use this, along with our rasterized vectors, to select and investigate values from a raster using boolean indexing.\n",
    "\n",
    "To start, we'll open our dem raster - note that this raster has the same georeferencing information as our landcover raster, so we don't have to load all of that information, just the raster band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open('data_files/NI_DEM.tif') as dataset:\n",
    "    dem = dataset.read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-airplane",
   "metadata": {},
   "source": [
    "From the previous section, we have an array with values corresponding each of the counties of Northern Ireland. Using `numpy`, we can use this array to select elements of other rasters by creating a _mask_, or a boolean array - that is, an array with values of `True` and `False`. For example, we can create a mask corresponding to County Antrim (`COUNTY_ID=1`) like this:\n",
    "\n",
    "```python\n",
    "county_antrim = county_mask == 1\n",
    "```\n",
    "Let's see what this mask looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_antrim = county_mask == 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.imshow(county_antrim) # visualize the rasterized output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-albania",
   "metadata": {},
   "source": [
    "We can also combine expressions using functions like [`np.logical_and()`](https://numpy.org/doc/stable/reference/generated/numpy.logical_and.html) or [`np.logical_or()`](https://numpy.org/doc/stable/reference/generated/numpy.logical_or.html). If we wanted to create a mask corresponding to both County Antrim (`county_mask == 3`) and County Down (`county_mask == 1`), we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "antrim_and_down = np.logical_or(county_mask == 3, county_mask == 1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.imshow(antrim_and_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-soccer",
   "metadata": {},
   "source": [
    "We could then find the mean elevation of these two counties by indexing, or selecting, pixels from `dem` using our mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_elevation = dem[antrim_and_down] # index the array using the antrim_and_down mask\n",
    "print('Mean elevation: {:.2f} m'.format(ad_elevation.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-dryer",
   "metadata": {},
   "source": [
    "Now let's say we wanted to investigate the two types of woodland we have, broadleaf and conifer. One thing we might want to look at is the area-elevation distribution of each type. To do this, we first have to select the pixels from the DEM that correspond to the broadleaf woodlands, and all of the pixels corresponding to conifer woodlands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_els = dem[landcover == 1] # get all dem values where landcover = 1\n",
    "conif_els = dem[landcover == 2] # get all dem values where landcover = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-awareness",
   "metadata": {},
   "source": [
    "Now, we have two different arrays, `broad_els` and `conif_els`, each corresponding to the DEM pixel values of each landcover type. We can plot a histogram of these arrays using `plt.hist()` ([documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html)), but this will only tell us the number of pixels - to work with areas, remember that we have to convert the pixel counts into areas by multiplying with the pixel area (here, 100 m x 100 m).\n",
    "\n",
    "First, though, we can use `numpy.histogram()` ([documentation](https://numpy.org/doc/stable/reference/generated/numpy.histogram.html)), along with an **array** representing our elevation bins, to produce a count of the number of pixels with an elevation that falls within each bin. We'll use `numpy.arange()` ([documentation](https://numpy.org/doc/stable/reference/generated/numpy.arange.html)) to generate an **array** of elevation bins ranging from 0 to 600 meters, spaced by 5 meters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_bins = np.arange(0, 600, 5) # create an array of values ranging from 0 to 600, spaced by 5.\n",
    "\n",
    "broad_count, _ = np.histogram(broad_els, el_bins) # bin the broadleaf elevations using the elevation bins\n",
    "conif_count, _ = np.histogram(conif_els, el_bins) # bin the conifer elevations using the elevation bins\n",
    "\n",
    "broad_area = broad_count * 100 * 100 # convert the pixel counts to an area by multipling by the pixel size in x, y\n",
    "conif_area = conif_count * 100 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-hostel",
   "metadata": {},
   "source": [
    "Finally, we can plot the area-elevation distribution for each land cover type using `plt.bar()` ([documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8)) # create a new figure and axes object\n",
    "\n",
    "# plot the area-elevation distributions using matplotlib.pyplot.bar(), converting from sq m to sq km:\n",
    "_ = ax.bar(el_bins[:-1], broad_area / 1e6, align='edge', width=5, alpha=0.8, label='Broadleaf Woodland')\n",
    "_ = ax.bar(el_bins[:-1], conif_area / 1e6, align='edge', width=5, alpha=0.8, label='Conifer Woodland')\n",
    "\n",
    "ax.set_xlim(0, 550) # set the x limits of the plot\n",
    "ax.set_ylim(0, 30) # set the y limits of the plot\n",
    "\n",
    "ax.set_xlabel('Elevation (m)') # add an x label\n",
    "ax.set_ylabel('Area (km$^2$)') # add a y label\n",
    "ax.legend() # add a legend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-juice",
   "metadata": {},
   "source": [
    "From this, we can clearly see that Conifer woodlands tend to be found at much higher elevations than Broadleaf woodlands, and at a much larger range of elevations (0-500 m, compared to 0-250 m or so). \n",
    "\n",
    "With these samples (`broad_els`, `conif_els`), we can also calculate statistics for each of these samples using `numpy` functions such as `np.mean()` ([documentation](https://numpy.org/doc/stable/reference/generated/numpy.mean.html)), `np.median()` ([documentation](https://numpy.org/doc/stable/reference/generated/numpy.median.html)), `np.std()` ([documentation](https://numpy.org/doc/stable/reference/generated/numpy.std.html)), and so on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Broadleaf mean elevation: {:.2f} m'.format(np.mean(broad_els)))\n",
    "print('Broadleaf median elevation: {:.2f} m'.format(np.median(broad_els)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a73bf9",
   "metadata": {},
   "source": [
    "<span style=\"color:#009fdf;font-size:1.1em;font-weight:bold\">Of the 10 different landcover types shown here, which one has the highest mean elevation? What about the largest spread in elevation values?</span>\n",
    "\n",
    "Starting from the initial code in the cell below, create a **DataFrame** of descriptive statistics of the elevation for each landcover type, which will help you answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new pandas DataFrame with 6 columns\n",
    "landcover_els = pd.DataFrame(columns=['name', 'mean', 'median', 'std. dev', 'max', 'min', 'range']) \n",
    "\n",
    "landcover_els['name'] = short_names # add the short names to the 'name' column\n",
    "\n",
    "# now, write a loop that will populate the table with descriptive statistics about the elevation\n",
    "# of each landcover class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-melissa",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "That's all for this practical. In lieu of an additional exercise this week, spend some time working on your project - are there concepts or examples from this practical that you can incorporate into your project?\n",
    "\n",
    "### Footnotes\n",
    "[<sup id=\"fn1\">1</sup>](#fn1-back)Rowland, C.S.; Morton, R.D.; Carrasco, L.; McShane, G.; O'Neil, A.W.; Wood, C.M. (2017). Land Cover Map 2015 (25m raster, N. Ireland). NERC Environmental Information Data Centre. [doi:10.5285/47f053a0-e34f-4534-a843-76f0a0998a2f](https://doi.org/10.5285/47f053a0-e34f-4534-a843-76f0a0998a2f)</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
