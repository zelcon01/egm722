# This section installs packages needed to run the script. 

import folium # Importing GeoJson class from folium library for visualizing geospatial data
import json # Importing json module for working with JSON data
import os # Importing os module for accessing operating system dependent functionality
import pandas as pd # Importing pandas library and aliasing it as pd for data analysis and manipulation
import matplotlib.pyplot as plt # Importing pyplot module from matplotlib library and aliasing it as plt for plotting
import scipy.signal # Importing signal module from scipy library for signal processing
import numpy as np # Importing numpy library and aliasing it as np for numerical computing
import geopandas as gpd # Importing geopandas library and aliasing it as gpd for working with geographic data
import openeo # Importing openeo library for working with the OpenEO API for Earth Observation data processing
from shapely.geometry import shape # Importing shape class from geometry module of shapely library for geometric operations
from shapely.geometry import Point # Importing Point class from geometry module of shapely library for representing a point in space
import rasterio
import xarray


#This establishes a connection with the Sentenel satelite data. 

connection = openeo.connect(url="openeo.dataspace.copernicus.eu")
connection.authenticate_oidc()

#if this does not read as 'Authorised successfully' or 'Authenticated', then please ensure that you have completed the setup steps as outlined in section 2.6 of the user guide. 
#if you have followed the steps in section 2.6 correctly and the problem persists, please look at https://dataspace.copernicus.eu/news for any information about service interruptions. 
#if there is no news of service problems you can raise a ticket here: https://helpcenter.dataspace.copernicus.eu/hc/en-gb/requests/new


# This section displays a list of all the PreZero landfill sites

landfill_5000m = gpd.read_file(r"C:\GIS_Course\EGM722\Project\Data\PZ_landfill_point4326.geojson")

landfill_5000m


# This section displays a map of all the PreZero landfill sites. Click any site for its name. 

# This creates the map and centres it on the geometries. 
centroids = landfill_5000m.geometry.centroid
center = [centroids.y.mean(), centroids.x.mean()]
site_map = folium.Map(location=center, zoom_start=5)

# Adding the landfill locations to the map
for feature in landfill_5000m.iterfeatures():
    # Extract feature number from properties
    feature_number = feature['properties']['Landfill']
    
    # Extract coordinates of the feature
    coordinates = feature['geometry']['coordinates']
    
    # Create a marker with label for each feature
    folium.Marker(location=[coordinates[1], coordinates[0]], 
                  popup=f"Feature {feature_number}").add_to(site_map)

# Display the map
site_map

# the warning "...Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect..." can be ignored. 


# This section appplies a buffer of 5000m to each landfill for the analysis.

# The  dataset is projected in EPSG:4326 with its units in degrees. This needs to be converted to CRS to EPSG:2062, which is in metres. 
landfill_5000m = landfill_5000m.to_crs(epsg=2062)

# Now the dataframe is converted, a buffer of 5000m is added to each point
landfill_5000m['geometry'] = landfill_5000m.buffer(5000)

# Now the buffered data needs to be converted back to EPSG:4326 because the Sentinel data is projected in EPSG:4326.
landfill_5000m = landfill_5000m.to_crs(epsg=4326)

# The time series analysis requires that A GeoJSON format file is used for the analised areas, so this bit produces a file suitable for that.
landfill_5000m_geojson = landfill_5000m.__geo_interface__


# This selects the specific dataset for the time series analysis. 

s5cube_timeseries = connection.load_collection(
    "SENTINEL_5P_L2", #This selects the data from the Sentinel 5 Precursor satelite. 
    temporal_extent=["2021-08-01", "2021-10-31"], # Select a date range using the format YYYY-MM-DD
    bands=["CH4"], # The options for gas monitoring are: 'CO', 'HCHO', 'NO2', 'O3', 'SO2', 'CH4'
)


# This takes the mean values of the selected gas within each of the buffered landfill geometries for every dataset within the selected time period. 
# Sentinel 5P will provide daily values as

timeseries = s5cube_timeseries.aggregate_spatial(geometries=landfill_5000m_geojson, reducer="mean")

#This saves the results as a .CSV file which can be viewed in Microsoft Excel or a similar package. It will be saved in the indicated location.
job = timeseries.execute_batch(out_format="CSV", title="CH4 timeseries")

job.get_results().download_file("CH4-results/CH4_timeseries.csv")








pd.read_csv("CH4-results/CH4_timeseries.csv", index_col=0)



def plot_timeseries(filename, figsize=(15, 10)):
    df = pd.read_csv(filename, index_col=0)
    df.index = pd.to_datetime(df.index)
    df = df.sort_index()

    fig, ax = plt.subplots(figsize=figsize, dpi=90)
    df.groupby("feature_index")["avg(band_0)"].plot(marker="o", ax=ax)
    ax.set_title(filename.split("/")[-1])
    ax.set_ylabel("CH4")
    ax.set_ylim(1800, 2000)
    ax.legend(title="parcel id", loc='upper left', bbox_to_anchor=(1.02, 1), ncol=2)
    ax.xaxis.set_major_locator(plt.MaxNLocator(20))
    ax.grid(True)



plot_timeseries("CH4-results/CH4_timeseries.csv")



cube = connection.load_collection(
    collection_id="SENTINEL_5P_L2",
    temporal_extent=["2021-10-14", "2021-10-14"],
    spatial_extent={"west": -10.5, "south": 35.5, "east": 3.6, "north": 44.5},
    bands=["CH4"],
)

cube.download("Sentinel-5P_Spain.GTiff")

#cube = connection.load_collection(
#  collection_id='SENTINEL_5P_L2',
#  temporal_extent=['2021-10-25', '2021-10-25'], # select the date you wish to view
#  spatial_extent={'west': -5.360168, 'south': 38.320048, 'east': -3.040865, 'north': 40.02087, 'espg': 4326},
#  bands=['CH4']
#)

#cube.execute_batch(outputfile='Sentinel5P_Spain1.nc',
#  title='Sentinel-5P Spain'
#)





# https://dataspace.copernicus.eu/news/2023-9-28-accessing-sentinel-mission-data-new-copernicus-data-space-ecosystem-apis


import rasterio
from rasterio import warp

# Define the destination CRS (EPSG:3857 - Web Mercator)
dst_crs = 'EPSG:3857'

# Open the source GeoTIFF file
with rasterio.open('Sentinel-5P_Spain.GTiff') as src:
    # Calculate the default transformation parameters for reprojection
    transform, width, height = rasterio.warp.calculate_default_transform(
        src.crs, dst_crs, src.width, src.height, *src.bounds)
    
    # Copy the metadata from the source dataset
    kwargs = src.meta.copy()
    # Update the metadata with the new CRS, transform, width, and height
    kwargs.update({
        'crs': dst_crs,
        'transform': transform,
        'width': width,
        'height': height
    })
    
    # Create a new GeoTIFF file with the reprojected data
    with rasterio.open('Sentinel-5P_Spain3857.GTiff', 'w', **kwargs) as dst:
        # Loop through each band in the source dataset
        for ind in range(1, src.count + 1):
            # Reproject each band and write it to the destination dataset
            rasterio.warp.reproject(
                source=rasterio.band(src, ind),
                destination=rasterio.band(dst, ind),
                src_transform=src.transform,
                src_crs=src.crs,
                dst_transform=transform,
                dst_crs=dst_crs,
                resampling=rasterio.warp.Resampling.nearest)



import folium
import rasterio
from rasterio import warp
import numpy as np
from matplotlib import cm

# normalize to 0-100 scale for color ramp purposes
raster_in = r'C:/GIS_Course/EGM722/Project/Sentinel-5P_Spain3857.GTiff'

dataset= rasterio.open(raster_in, 'r') # open raster file

rasdata = dataset.read()[0] # read raster vals into numpy array

rasdata_normed = rasdata/rasdata.max() * 10 # normalization to help with color gradient

# set bounds using wgs84 projection (geotiff is in web mercator)
dest_crs = 'EPSG:3857'
left, bottom, right, top = [i for i in dataset.bounds]
bounds_4326 = warp.transform_bounds(src_crs=dataset.crs, dst_crs=dest_crs, left=left, 
                               bottom=bottom, right=right, top=top)

# Choose a suitable colormap
colormap = cm.turbo  # Access colormap directly from matplotlib.colormaps



# Normalize data, ignoring zero values
non_zero_values = rasdata[rasdata != 0]
normalized_data = (non_zero_values - non_zero_values.min()) / (non_zero_values.max() - non_zero_values.min())

# Create a colormap index array for the non-zero values
colormap_index = np.zeros_like(rasdata, dtype=np.float64)
colormap_index[rasdata != 0] = normalized_data

PZ_landfill_Locations = gpd.read_file(r"C:\GIS_Course\EGM722\Project\Data\PZ_landfill_point4326.geojson")

Test_landfill_Location = gpd.read_file(r"C:\GIS_Course\EGM722\Project\Data\test_landfill.geojson")

# Map it out!
m = folium.Map([40.4168, -4.7038], zoom_start=8)
folium.GeoJson(PZ_landfill_Locations).add_to(m)
folium.GeoJson(Test_landfill_Location).add_to(m)
folium.raster_layers.ImageOverlay(
    image=colormap(colormap_index),
    name='sample map',
    opacity=0.5,
    bounds=[[35.5, -10.5], [44.4, 3.6]],  # Specify bounds using (latitude, longitude) order
    interactive=False,
    cross_origin=False,
    zindex=1
).add_to(m)
folium.LayerControl().add_to(m)

# Add the GeoJSON object to the map
m





#import xarray

...

# Load the netCDF data set
#data_set = xarray.load_dataset("Sentinel-5P Spain2.nc")

# Pick desired band, e.g. assuming there is an "NDVI" band:
#ndvi = data_set["CH4"]

# Pick first time label and visualize
#ndvi.isel(t=0).plot.imshow()



