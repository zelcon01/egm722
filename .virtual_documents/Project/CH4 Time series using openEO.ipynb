import folium # Importing GeoJson class from folium library for visualizing geospatial data
import json # Importing json module for working with JSON data
import os # Importing os module for accessing operating system dependent functionality
import pandas as pd # Importing pandas library and aliasing it as pd for data analysis and manipulation
import matplotlib.pyplot as plt # Importing pyplot module from matplotlib library and aliasing it as plt for plotting
import scipy.signal # Importing signal module from scipy library for signal processing
import numpy as np # Importing numpy library and aliasing it as np for numerical computing
import geopandas as gpd # Importing geopandas library and aliasing it as gpd for working with geographic data
import openeo # Importing openeo library for working with the OpenEO API for Earth Observation data processing
from shapely.geometry import shape # Importing shape class from geometry module of shapely library for geometric operations
from shapely.geometry import Point # Importing Point class from geometry module of shapely library for representing a point in space
import rasterio
import xarray


connection = openeo.connect(url="openeo.dataspace.copernicus.eu")
connection.authenticate_oidc()


# Load the GeoJSON file as a GeoDataFrame
#landfill_1500m = gpd.read_file(r"C:\GIS_Course\EGM722\Project\Data\PZ_landfill_point4326.geojson")

# Convert the CRS to EPSG:2062
#landfill_1500m = landfill_1500m.to_crs(epsg=2062)

# Add a buffer of 1000m to each point
#landfill_1500m['geometry'] = landfill_1500m.buffer(1000)

# Convert the CRS back to EPSG:4326
#landfill_1500m = landfill_1500m.to_crs(epsg=4326)

# Convert from dataframe to GeoJSON
#landfill_1500m_geojson = landfill_1500m.__geo_interface__

# Load the GeoJSON point file while the buffer isn't working
def read_json(filename: str) -> dict:
  with open(filename,encoding="utf-8") as input:
    field = json.load(input)
    return field

landfill = read_json(r"C:\GIS_Course\EGM722\Project\Data\PZ_landfill_point4326.geojson")



s5cube_timeseries = connection.load_collection(
    "SENTINEL_5P_L2",
    temporal_extent=["2023-02-01", "2023-03-01"],
    bands=["CH4"], # options for gas monitoring 'CO', 'HCHO', 'NO2', 'O3', 'SO2', 'CH4'
)





timeseries = s5cube_timeseries.aggregate_spatial(geometries=landfill, reducer="mean")



job = timeseries.execute_batch(out_format="CSV", title="CH4 timeseries")


job.get_results().download_file("CH4-results/CH4_timeseries.csv")

pd.read_csv("CH4-results/CH4_timeseries.csv", index_col=0)



def plot_timeseries(filename, figsize=(15, 10)):
    df = pd.read_csv(filename, index_col=0)
    df.index = pd.to_datetime(df.index)
    df = df.sort_index()

    fig, ax = plt.subplots(figsize=figsize, dpi=90)
    df.groupby("feature_index")["avg(band_0)"].plot(marker="o", ax=ax)
    ax.set_title(filename.split("/")[-1])
    ax.set_ylabel("CH4")
    ax.set_ylim(1800, 2000)
    ax.legend(title="parcel id", loc='upper left', bbox_to_anchor=(1.02, 1), ncol=2)
    ax.xaxis.set_major_locator(plt.MaxNLocator(20))
    ax.grid(True)



plot_timeseries("CH4-results/CH4_timeseries.csv")




# https://dataspace.copernicus.eu/news/2023-9-28-accessing-sentinel-mission-data-new-copernicus-data-space-ecosystem-apis


datacube = connection.load_collection(
  "SENTINEL_5P_L2",
  spatial_extent={"west": -4.175611, "south": 39.852203, "east": -4.152131, "north": 39.870274},
  temporal_extent=["2020-01-01", "2021-01-01"],
  bands=["CH4"]
)

datacube.execute_batch(
    title="landfill8",
     outputfile="landfill8.nc"
)
#load the saved file
dataset = xr.load_dataset("landfill8.nc")

cube = connection.load_collection(
  collection_id='SENTINEL_5P_L2',
  temporal_extent=['2020-02-01', '2020-02-30'],
  spatial_extent={"west": -4.175611, "south": 39.852203, "east": -4.152131, "north": 39.870274},
  bands=['CH4']
)

cube.execute_batch(outputfile='Sentinel5P_Lanfill0.nc',
  title='Sentinel5P_Lanfill0',
  description='benchmarking-creo',
  job_options={'driver-memory': '1g'}
                
)







